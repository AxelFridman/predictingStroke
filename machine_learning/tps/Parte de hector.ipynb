{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx4PVF0sqXnbGdKkDn7Hd1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lkqtcbBpd9V8"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Hector"],"metadata":{"id":"07_TSmXM8juP"}},{"cell_type":"markdown","source":["### Otros modelos\n","\n","---\n","\n"],"metadata":{"id":"7zjy9DteAA8_"}},{"cell_type":"markdown","source":["**SVM**"],"metadata":{"id":"pp3YBl6QEC03"}},{"cell_type":"code","source":["!pip install import_ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSo9fXmuAWQD","executionInfo":{"status":"ok","timestamp":1669335415313,"user_tz":180,"elapsed":5017,"user":{"displayName":"Noé Fabián Hsueh","userId":"07390508128735630594"}},"outputId":"81091582-5471-4aab-8be4-72c4ea86ba93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.7.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.2)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.13.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (3.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"1mOiSEPNkLEJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669335417073,"user_tz":180,"elapsed":1769,"user":{"displayName":"Noé Fabián Hsueh","userId":"07390508128735630594"}},"outputId":"66130019-89e8-4622-8a46-8874b8a98928"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd \"/content/gdrive/My Drive/Machine Learning/TP3\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWncKqy_92e4","executionInfo":{"status":"ok","timestamp":1669335417663,"user_tz":180,"elapsed":598,"user":{"displayName":"Noé Fabián Hsueh","userId":"07390508128735630594"}},"outputId":"17568435-72db-40a6-b2a0-87711ef215e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/gdrive/My Drive/Machine Learning/TP3'\n","/content\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHm_u9drjswa","executionInfo":{"status":"ok","timestamp":1669335417663,"user_tz":180,"elapsed":27,"user":{"displayName":"Noé Fabián Hsueh","userId":"07390508128735630594"}},"outputId":"09ab833f-fc88-4b84-8210-2f2a26ff21d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"CYO0cfsrjT4W","executionInfo":{"status":"error","timestamp":1669335418155,"user_tz":180,"elapsed":494,"user":{"displayName":"Noé Fabián Hsueh","userId":"07390508128735630594"}},"outputId":"81da2ec7-78dc-48e0-b008-364207292a3a"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-104-e6f79dda5ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalibration_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBMI_imputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmokingStatus_imputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Lib'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import import_ipynb\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline, make_union\n","from sklearn.compose import ColumnTransformer, make_column_transformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.calibration import calibration_curve\n","\n","from Lib import Evaluator\n","from Lib import BMI_imputer\n","from Lib import SmokingStatus_imputer\n","from Lib import graficar_distribuciones_Train_Data\n","from Lib import graficar_distribuciones_Dev_Data\n","from Lib import flatten\n","from sklearn.metrics import log_loss\n","from matplotlib import pyplot\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","import math"]},{"cell_type":"markdown","source":["### Path to the data on Drive"],"metadata":{"id":"hxmCDDwIkPFh"}},{"cell_type":"code","source":["#path axel\n","# DATA_HOME = r\"/content/gdrive/My Drive/UBA/machine_learning/tp1\"\n","# path Noe \n","# DATA_HOME = r\"/content/gdrive/My Drive/tp1\"\n","# path Hector\n","\n","DATA_HOME = r\"/content/gdrive/MyDrive/Machine Learning/TP1/\"\n","df = pd.read_csv(\n","    DATA_HOME + \"/healthcare-dataset-stroke-data.csv\"\n",")"],"metadata":{"id":"a6zpMv9gkNz5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"iioobAW2kZmo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crear las pipelines de operaciones sobre los datos"],"metadata":{"id":"1tHwmcvay6xw"}},{"cell_type":"code","source":["bmi = ['bmi']\n","numericas = ['age', 'hypertension', 'avg_glucose_level']\n","categoricas = [\"gender\", \"ever_married\",\"smoking_status\",\"heart_disease\"]\n","\n","# pipelines para bmi y otras variables numericas\n","imputer_pipe = make_pipeline(\n","    SimpleImputer(missing_values=np.nan, strategy='mean'), \n",")\n","\n","scaler_pipe = make_pipeline(\n","     StandardScaler()\n",")\n","# pipelines para variables categórcias\n","one_hot_pipe = make_pipeline(\n","    OneHotEncoder()\n",")\n","# preprocessor  sin modelado de missing values\n","preprocessor = make_column_transformer(\n","    (imputer_pipe, bmi),\n","    (scaler_pipe, numericas), \n","    (one_hot_pipe, categoricas))\n","\n","# preprocessor con modelado de missing value \n","preprocessor2 = make_pipeline(\n","    make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","    ), \n","    IterativeImputer(random_state=42)\n",")"],"metadata":{"id":"mg8ytyP08qj9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imputamos bmi con una regresión lineal para predecir los missing values"],"metadata":{"id":"atrK3fkpGxj2"}},{"cell_type":"code","source":["pipe_bmi_lr = make_pipeline(\n","    BMI_imputer(\"bmi\"),\n","    make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","    ) \n"," ) "],"metadata":{"id":"kntOx9-bJ1tB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imputamos SmokingStatus con un árbol de decisión para predecir los missing values"],"metadata":{"id":"Z6U_Di5zGmVl"}},{"cell_type":"code","source":["pipe_ModelImputer = make_pipeline(\n","     BMI_imputer(\"bmi\"), \n","     SmokingStatus_imputer(\"smoking_status\"),\n","     make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","      )\n","    ) "],"metadata":{"id":"ahIZcgUJGIOB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualizar Diagramas de los pipelines de preprocesamiento de datos "],"metadata":{"id":"E9lEEfNB00DD"}},{"cell_type":"code","source":["# visualizar diagrama \n","from sklearn import set_config\n","set_config(display='diagram')\n","display(preprocessor) "],"metadata":{"id":"heloCQGjL5GU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_config(display='diagram')\n","display(preprocessor2) "],"metadata":{"id":"OHQTFctnQGsA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Establecer las pipelines con los modelos"],"metadata":{"id":"xhkICG4_288d"}},{"cell_type":"code","source":["SVM_Uncalibrated_pipe = make_pipeline(\n","    preprocessor, # con simpleImputer\n","    svm.SVC(random_state = 420, kernel = 'rbf', gamma = 0.7, C = 1.0,\n","        class_weight= 'balanced')  \n",")\n","\n","SVM2_Uncalibrated_pipe = make_pipeline(\n","    preprocessor2, # con IterativeImputer\n","    svm.SVC(random_state = 420, kernel = 'rbf', gamma = 0.7, C = 1.0,\n","        class_weight= 'balanced')\n",")\n","\n","SVM3_Uncalibrated_pipe  = make_pipeline(\n","    pipe_bmi_lr, # BMI Nan imputado con regresion lineal\n","    svm.SVC(random_state = 420, kernel = 'rbf', gamma = 0.7, C = 1.0,\n","        class_weight= 'balanced')\n",")\n","\n","SVM4_Uncalibrated_pipe  = make_pipeline(\n","    pipe_ModelImputer, # BMI Nan imputado con regresion lineal y SmokingStatus imputao con DTC\n","    svm.SVC(random_state = 420, kernel = 'rbf', gamma = 0.7, C = 1.0,\n","        class_weight= 'balanced')\n",")"],"metadata":{"id":"lPJgZMvRN142"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Comparar la efectividad de un modelo SVM descalibrado con uno calibrado"],"metadata":{"id":"k2CmnIMT7jU_"}},{"cell_type":"markdown","source":["### SVM descalibrado"],"metadata":{"id":"RRiyEPFE1nFk"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.fit_and_eval_pipe('UncalibratedSMV', SVM_Uncalibrated_pipe)"],"metadata":{"id":"ccCd_MaPPUGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SVM_Uncalibrated_pipe.fit(xtrain, ytrain)\n","probs = SVM_Uncalibrated_pipe.decision_function(xdev)\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle='--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"fRe6kB6yOIfl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM calibrado"],"metadata":{"id":"JNPFoWO3uPqU"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.eval_pipe_calibrated('UncalibratedSMV', SVM_Uncalibrated_pipe)"],"metadata":{"id":"FqTHMBqi_ZBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","ev = Evaluator(xtrain, ytrain, xdev, ydev)\n","ev.make_calibration_curve('UncalibratedSMV', SVM_Uncalibrated_pipe)"],"metadata":{"id":"uI6sBukVuZQD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Distribuciones de la variable respuesta con el Train Set"],"metadata":{"id":"yNSk3q_86o2-"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(SVM_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Train_Data(xtrain, ytrain, calibrated)"],"metadata":{"id":"xQipbkMNd_iF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Distribuciones de la variable respuesta con el Dev Set\n"],"metadata":{"id":"yrMlEcTu64yE"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(SVM_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Dev_Data(xdev, ydev, calibrated)"],"metadata":{"id":"g6EN6wJl6_qU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Comparar la efectividad de los modelos SVM entrenados y probados con datasets preprocesados de tres manera diferentes "],"metadata":{"id":"ka53letg7CGq"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","\n","ev.eval_pipe_calibrated('solo SVM con SimpleImputer', SVM_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('SVM con IterativeImputer de bmi', SVM2_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('SVM con regresion de bmi', SVM3_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('SVM con regresion de bmi y DTC en ss', SVM4_Uncalibrated_pipe)\n","\n","pd.DataFrame(ev.evaluations)"],"metadata":{"id":"XrDlkGn35CFW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Selección de Hiperparámetros en modelos SVM"],"metadata":{"id":"svUXivsShfP2"}},{"cell_type":"code","source":["from pprint import pprint\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from time import time\n","\n","\n","def objective(params):\n","    print(params)\n","    SVMUncalibrated_pipe = make_pipeline(\n","    preprocessor, \n","    svm.SVC(random_state = 435, kernel = 'rbf', class_weight= 'balanced', **params)  \n","    )\n","    t0 = time()\n","    calibrated = CalibratedClassifierCV(SVMUncalibrated_pipe, method = 'isotonic', cv = 10)\n","    calibrated.fit(xtrain, ytrain)\n","    train_time = time() - t0\n","    trainloss = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1])\n","    devloss = log_loss(ydev, calibrated.predict_proba(xdev)[:,1])\n","    testloss = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","    print(f'trainloss {trainloss:.02f}', f'devloss {devloss:.02f}', f'testloss {testloss:.02f}')\n","    return dict(\n","        tr_loss = trainloss,\n","        loss = devloss,\n","        test_loss = testloss,\n","        params = params,\n","        train_time = train_time,\n","        status=STATUS_OK\n","    )\n"],"metadata":{"id":"x89d-Cr_e312"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["space = {\n","    'gamma': hp.loguniform('gamma', low = np.log(0.01), high = np.log(3)),\n","    'C': hp.loguniform('C value', low = np.log(0.01), high = np.log(10)),\n","}\n","\n","trials = Trials()"],"metadata":{"id":"b0IC03g-x6rR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","gamma = hp.loguniform('gamma', low = np.log(0.01), high = np.log(3))\n","samples = [hyperopt.pyll.stochastic.sample(gamma) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"13YqStmsTgwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Cvalue = hp.loguniform('C value', low = np.log(0.01), high = np.log(10))\n","samples = [hyperopt.pyll.stochastic.sample(Cvalue) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"ZcuHxaNth34E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials)"],"metadata":{"id":"WirodcsS_lF_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mostrar los mejores modelos"],"metadata":{"id":"yec_OCt7Amu0"}},{"cell_type":"code","source":["df_res_hyperopt = pd.DataFrame(list(map(flatten, [e['result'] for e in trials.trials])))\n","df_res_hyperopt.sort_values('loss').head()"],"metadata":{"id":"Gno9SK94APBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Guardar el dataframe (Descargarlo o cambiar el path para preservarlo)"],"metadata":{"id":"Q60q2PKTmBd9"}},{"cell_type":"code","source":["#df_res_hyperopt.to_pickle(\"df_res_hyperopt\")\n","\n","# Para cargar el archivo de vuelta: \n","# df_res_hyperopt = pd.read_pickle(\"df_res_hyperopt\") "],"metadata":{"id":"cDYq7R-pmBKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_res_hyperopt = pd.read_pickle(\"/content/gdrive/MyDrive/Machine Learning/TP3/df_res_hyperopt_SVM\") "],"metadata":{"id":"9mJB89Lp1ed4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Graficar los errores de Train (naranja) y Dev (azul) y mostrar el mejor modelo "],"metadata":{"id":"Wa8KwWMFA6hN"}},{"cell_type":"code","source":["df_res_hyperopt.loss.plot(style='-o', alpha=0.5)\n","plt.scatter([df_res_hyperopt.loss.argmin()], [df_res_hyperopt.loss.min()], c='r')\n","df_res_hyperopt.tr_loss.plot()\n","plt.yscale('log')\n","plt.grid()"],"metadata":{"id":"DvMs8TopAfBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,6))\n","plt.scatter(df_res_hyperopt.tr_loss, df_res_hyperopt.loss, c=(df_res_hyperopt.loss-df_res_hyperopt.tr_loss)/df_res_hyperopt.loss*100)\n","plt.title('Comparison of training and dev losses.\\n Color corresponds to overfitting percentage')\n","plt.colorbar()\n","m = min(df_res_hyperopt.tr_loss.min(), df_res_hyperopt.loss.min())\n","M = max(df_res_hyperopt.tr_loss.max(), df_res_hyperopt.loss.max())\n","plt.plot([m, M], [m, M], 'k--')\n","plt.xlabel('tr loss')\n","plt.ylabel('dev loss')\n","plt.grid()"],"metadata":{"id":"m7zlGCYTB9m6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mostrar la distribución de los hiperparámetros para los mejores y peores modelos"],"metadata":{"id":"5FFTblK5hVUh"}},{"cell_type":"code","source":["df = df_res_hyperopt\n","cut_point = df.loss.median()\n","best_models_df = df[df.loss <= cut_point]\n","worst_models_df = df[df.loss > cut_point]\n","\n","def visualize_param(param_name):\n","  s = df[f'params.{param_name}']\n","  if s.dtype.name == 'object':\n","    visualize_categorical_param(param_name)\n","  else: # assume numerical\n","    visualize_numerical_param(param_name)\n","\n","def visualize_categorical_param(param_name):\n","    pd.concat([\n","      best_models_df[f'params.{param_name}'].value_counts().rename('best'),\n","      worst_models_df[f'params.{param_name}'].value_counts().rename('worst')\n","  ], axis=1).plot.bar()\n","\n","def visualize_numerical_param(param_name):\n","  plt.violinplot([\n","      best_models_df[f'params.{param_name}'],\n","      worst_models_df[f'params.{param_name}']\n","  ])\n","  plt.xticks([1, 2], ['best', 'worst'])"],"metadata":{"id":"oTJZxlPQclkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_names = list(trials.trials[0]['result']['params'].keys())\n","for param_name in param_names:\n","  plt.figure()\n","  visualize_param(param_name)\n","  plt.title(param_name)\n","  plt.tight_layout()"],"metadata":{"id":"qEmzr1veAg5U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Buscar el modelo que menos sobreajusta"],"metadata":{"id":"7_n_u81yZ4xl"}},{"cell_type":"code","source":["# El que menos overfittea de los mejors\n","best = df[df.loss < df.loss.min() * 1.001].sort_values('tr_loss', ascending = False).head(30)\n","best"],"metadata":{"id":"VQNfk2ZdZ4CW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM  calibrado y optimizado"],"metadata":{"id":"2lU41NOihukc"}},{"cell_type":"code","source":["params = {k.replace('params.', ''):v for k, v in best.iloc[0].to_dict().items() if 'params.' in k}\n","SVM_Uncalibrated_Pipe = make_pipeline(\n","    preprocessor, \n","    svm.SVC(random_state = 435, kernel = 'rbf', class_weight= 'balanced', **params)  \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(SVM_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes = dict(\n","            name = \"Mejor modelo SVM\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes"],"metadata":{"id":"D6LDdGhohULV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cambiando el \"preprocesor\" pipe por el \"pipe_ModelImputer\" pipe"],"metadata":{"id":"faIooHdeyI4T"}},{"cell_type":"code","source":["SVM_Uncalibrated_Pipe2 = make_pipeline(\n","    pipe_ModelImputer, \n","    svm.SVC(random_state = 435, kernel = 'rbf', class_weight= 'balanced', **params)  \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(SVM_Uncalibrated_Pipe2, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes2 = dict(\n","            name = \"Mejor modelo SVM\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes2"],"metadata":{"id":"I9ZN_Fh4z_SH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_time"],"metadata":{"id":"zeV2P1NSYUdg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluar el nivel de calibración de las probabilidades con un Diagrama de Confiabilidad"],"metadata":{"id":"C4zc6xgHRsiK"}},{"cell_type":"markdown","source":["### Calibración con el dataset de Development"],"metadata":{"id":"gi6AHkZoUtOb"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(SVM_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","probs = calibrated.predict_proba(xdev)[:,1]\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle = '--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"kEcWbE93TLYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Calibración con el dataset de Testing"],"metadata":{"id":"_2ZJ3wflU7FZ"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.make_calibration_curve('CalibratedSMV', SVM_Uncalibrated_Pipe)"],"metadata":{"id":"_ifno31fRsJD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**RF**"],"metadata":{"id":"gj6VmwsdkPLZ"}},{"cell_type":"code","source":["!pip install import_ipynb"],"metadata":{"id":"6d6SBA9DkTtJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"fF6v3wZDkTtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd \"/content/gdrive/My Drive/Machine Learning/TP3\"\n"],"metadata":{"id":"I1FVd6p8kTtL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"sDBl5XInkTtL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-6eRKbLkTtM"},"outputs":[],"source":["import import_ipynb\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline, make_union\n","from sklearn.compose import ColumnTransformer, make_column_transformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.calibration import calibration_curve\n","#from Lib import Evaluator\n","\n","from Lib import BMI_imputer\n","from Lib import SmokingStatus_toNan\n","from Lib import SmokingStatus_imputer\n","from Lib import graficar_distribuciones_Train_Data\n","from Lib import graficar_distribuciones_Dev_Data\n","from Lib import flatten \n","from sklearn.metrics import log_loss\n","from matplotlib import pyplot\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","import math"]},{"cell_type":"markdown","source":["### Path to the data on Drive"],"metadata":{"id":"ot-NAjCmkTtM"}},{"cell_type":"code","source":["DATA_HOME = r\"/content/gdrive/MyDrive/Machine Learning/TP1/\"\n","df = pd.read_csv(\n","    DATA_HOME + \"/healthcare-dataset-stroke-data.csv\"\n",")"],"metadata":{"id":"-4mMtDN_kTtN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"VV5qnVZOkTtN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Limpieza de observaciones malas y particion x e y"],"metadata":{"id":"5gKBgrQNRuSR"}},{"cell_type":"code","source":["df = df[df.gender != \"Other\"]\n","df = df.drop([\"work_type\",\t\"Residence_type\", \"id\"], axis=1)"],"metadata":{"id":"jeWFmXMJJKs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ydf = df[\"stroke\"]\n","xdf = df.loc[:, df.columns != \"stroke\"]"],"metadata":{"id":"AQTt5vZJJPE4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Division de dataset para validacion cruzada"],"metadata":{"id":"KRxpQtYkOAAN"}},{"cell_type":"code","source":["xtrain, xdev, ytrain, ydev = train_test_split(xdf, ydf, stratify=ydf, test_size=1/5, random_state=420)"],"metadata":{"id":"7Ys9w3-oJw6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xdev, xtest, ydev, ytest = train_test_split(xdev, ydev, stratify=ydev, test_size=1/2, random_state=420)"],"metadata":{"id":"GdnXxcfILD9z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txUoBDIdtkP_"},"outputs":[],"source":["from sklearn.metrics import log_loss\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.calibration import calibration_curve\n","from matplotlib import pyplot\n","\n","class Evaluator:\n","    def __init__(self, X_train, y_train, X_dev, y_dev, X_test=None, y_test=None):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.X_dev = X_dev\n","        self.y_dev = y_dev\n","        self.X_test = X_test\n","        self.y_test = y_test\n","        self.evaluations = []\n","\n","    def eval_pipe(self, model_name, pipe): \n","        res = self.eval_prediction(model_name, pipe.predict_proba(self.X_train)[:,1], pipe.predict_proba(self.X_dev)[:,1])\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, pipe.predict_proba(self.X_test)[:,1])\n","        return res\n","\n","    def fit_and_eval_pipe(self, model_name, pipe): \n","        pipe.fit(self.X_train, self.y_train)\n","        res = self.eval_prediction(model_name, pipe.decision_function(self.X_train), pipe.decision_function(self.X_dev))\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, pipe.decision_function(self.X_test))\n","        return res\n","\n","    def eval_pipe_calibrated(self, model_name, pipe): \n","        #calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv = 10)\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv = 10)\n","        calibrated.fit(self.X_train, self.y_train)\n","        res = self.eval_prediction(model_name, calibrated.predict_proba(self.X_train)[:,1], calibrated.predict_proba(self.X_dev)[:,1])\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, calibrated.predict_proba(self.X_test)[:,1])\n","        return res\n","\n","    def make_calibration_curve(self, model_name, pipe):\n","      if self.X_test is not None:\n","        # calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv=5)\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv=10)\n","        calibrated.fit(self.X_train, self.y_train)\n","        probs = calibrated.predict_proba(self.X_test)[:,1]\n","        # reliability diagram\n","        fop, mpv = calibration_curve(self.y_test, probs, n_bins = 10, normalize = True)\n","        # plot perfectly calibrated\n","        pyplot.plot([0, 1], [0, 1], linestyle='--')\n","        # plot model reliability\n","        pyplot.plot(mpv, fop, marker='.')\n","        pyplot.show()\n","      else:\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv=10)\n","        # calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv=5)\n","        calibrated.fit(self.X_train, self.y_train)\n","        probs = calibrated.predict_proba(self.X_dev)[:,1]\n","        # reliability diagram\n","        fop, mpv = calibration_curve(self.y_dev, probs, n_bins=10, normalize=True)\n","        # plot perfectly calibrated\n","        pyplot.plot([0, 1], [0, 1], linestyle='--')\n","        # plot model reliability\n","        pyplot.plot(mpv, fop, marker='.')\n","        pyplot.show()\n","\n","    def eval_prediction(self, model_name, y_hat_train, y_hat_dev):\n","        res = dict(\n","            name=model_name,\n","            train= log_loss(self.y_train, y_hat_train),\n","            dev  = log_loss(self.y_dev, y_hat_dev, )\n","        )\n","\n","        self.evaluations.append(res)\n","        return res"]},{"cell_type":"markdown","source":["### Crear las pipelines de operaciones sobre los datos"],"metadata":{"id":"PIFFKS14kTtQ"}},{"cell_type":"code","source":["bmi = ['bmi']\n","numericas = ['age', 'hypertension','avg_glucose_level']\n","categoricas = [\"gender\", \"ever_married\",\"smoking_status\",\"heart_disease\"]\n","\n","# pipes numericas\n","imputer_pipe = make_pipeline(\n","    SimpleImputer(missing_values=np.nan, strategy='mean'), \n",")\n","scaler_pipe = make_pipeline(\n","     StandardScaler()\n",")\n","# pipes categoricas\n","one_hot_pipe = make_pipeline(\n","    OneHotEncoder()\n",")\n","\n","# preprocessor 1  \n","preprocessor1 = make_column_transformer(\n","    (imputer_pipe, bmi),\n","    (scaler_pipe, numericas), \n","    (one_hot_pipe, categoricas))\n","\n","# preprocessor 2 \n","\n","preprocessor2 = make_pipeline(\n","    SmokingStatus_toNan(\"smoking_status\"),\n","    make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","    ), \n","    IterativeImputer(random_state=42)\n",")\n","\n","# preprocessor 3\n","preprocessor3 = make_pipeline(\n","     BMI_imputer(\"bmi\"), \n","     SmokingStatus_toNan(\"smoking_status\"),\n","     SmokingStatus_imputer(\"smoking_status\"),\n","     make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","      )\n","    )"],"metadata":{"id":"rAN31aZDkTtR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualizar Diagramas de los pipelines de preprocesamiento de datos "],"metadata":{"id":"Ajm3epkqkTtR"}},{"cell_type":"code","source":["# visualizar diagrama \n","from sklearn import set_config\n","set_config(display='diagram')\n","display(preprocessor1) "],"metadata":{"id":"g-fT8DaVkTtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_config(display='diagram')\n","display(preprocessor2) "],"metadata":{"id":"dFTFFsdGkTtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_config(display='diagram')\n","display(preprocessor3) "],"metadata":{"id":"qRN0BbU1gsht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Establecer las pipelines con los modelos"],"metadata":{"id":"Bv4LE6SakTtS"}},{"cell_type":"code","source":["RF1_Uncalibrated_pipe = make_pipeline(\n","    preprocessor1, \n","    RandomForestClassifier(random_state=420, class_weight = 'balanced')  \n",")\n","\n","RF2_Uncalibrated_pipe = make_pipeline(\n","    preprocessor2, \n","    RandomForestClassifier(random_state=420, class_weight = 'balanced') \n",")\n","\n","RF3_Uncalibrated_pipe  = make_pipeline(\n","    preprocessor3, \n","    RandomForestClassifier(random_state=420, class_weight = 'balanced') \n",")"],"metadata":{"id":"IAuzGm1lkTtT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Comparar la efectividad de un modelo RF descalibrado con uno calibrado"],"metadata":{"id":"Y6Oh5hVDkTtT"}},{"cell_type":"markdown","source":["RF descalibrado"],"metadata":{"id":"9PFveDwtkTtT"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","RF1_Uncalibrated_pipe.fit(xtrain, ytrain)\n","ev.eval_pipe('UncalibratedSMV', RF1_Uncalibrated_pipe)"],"metadata":{"id":"83bu_R1WkTtU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = RF1_Uncalibrated_pipe.predict_proba(xdev)[:,1]\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle='--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"0WCBa4IzkTtU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RF calibrado"],"metadata":{"id":"TbJqAnrYkTtU"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.eval_pipe_calibrated('UncalibratedSMV', RF1_Uncalibrated_pipe)"],"metadata":{"id":"yncRpS51kTtV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","ev = Evaluator(xtrain, ytrain, xdev, ydev)\n","ev.make_calibration_curve('UncalibratedSMV', RF1_Uncalibrated_pipe)"],"metadata":{"id":"Os76Z8mGkTtV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Distribuciones de la variable respuesta con el Train Set"],"metadata":{"id":"bHE-KsmKkTtW"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(RF1_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Train_Data(xtrain, ytrain, calibrated)"],"metadata":{"id":"YY8viLjykTtW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Distribuciones de la variable respuesta con el Dev Set\n"],"metadata":{"id":"pWqrUIQ0kTtW"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(RF1_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Dev_Data(xdev, ydev, calibrated)"],"metadata":{"id":"M4KXHEe_kTtW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparar la efectividad de los modelos RF entrenados y probados con datasets preprocesados de tres manera diferentes "],"metadata":{"id":"xztGQOJukTtX"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","\n","ev.eval_pipe_calibrated('solo RF con SimpleImputer', RF1_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('RF con IterativeImputer de bmi', RF2_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('RF con regresion de bmi y DTC en ss', RF3_Uncalibrated_pipe)\n","\n","pd.DataFrame(ev.evaluations)"],"metadata":{"id":"JorXkFcpkTtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Selección de Hiperparámetros en modelos RF"],"metadata":{"id":"wMv3-PSvkTtY"}},{"cell_type":"code","source":["from pprint import pprint\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from time import time\n","\n","\n","def objective(params):\n","    # Tenemos que hacer una adaptacion a nuestra funcion evaluate_model para que funcione con hyperopt\n","    if params['min_samples_split'] is not None:\n","        params['min_samples_split'] = int(params['min_samples_split'])\n","        params['max_features'] = int(params['max_features'])\n","        params['n_estimators'] = int(params['n_estimators'])\n","    print(params)\n","    RFUncalibrated_pipe = make_pipeline(\n","    preprocessor1, \n","    RandomForestClassifier(random_state = 420, class_weight= 'balanced', **params)  \n","    )\n","    t0 = time()\n","    calibrated = CalibratedClassifierCV(RFUncalibrated_pipe, method = 'isotonic', cv = 10)\n","    calibrated.fit(xtrain, ytrain)\n","    train_time = time() - t0\n","    trainloss = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1])\n","    devloss = log_loss(ydev, calibrated.predict_proba(xdev)[:,1])\n","    testloss = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","    print(f'trainloss {trainloss:.02f}', f'devloss {devloss:.02f}', f'testloss {testloss:.02f}')\n","    return dict(\n","        tr_loss = trainloss,\n","        loss = devloss,\n","        test_loss = testloss,\n","        params = params,\n","        train_time = train_time,\n","        status=STATUS_OK\n","    )\n"],"metadata":{"id":"4CvTs73VkTtY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["space = {\n","    'n_estimators': hp.loguniform('n_estimators', np.log(5), np.log(500)),\n","    'max_features': hp.uniform('max_features', 2, 8),\n","    'min_samples_split': hp.loguniform('min_samples_split', np.log(2), np.log(300))\n","}\n","\n","trials = Trials()"],"metadata":{"id":"QXWHsQ2mkTtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","n_estimators = hp.loguniform('gamma', low = np.log(0.01), high = np.log(3))\n","samples = [hyperopt.pyll.stochastic.sample(n_estimators) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"EcDgOTpFkTtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","max_features = hp.uniform('max_features', 2, 8)\n","samples = [hyperopt.pyll.stochastic.sample(max_features) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"wUFz-FLtallc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","min_samples_split = hp.loguniform('min_samples_split', np.log(2), np.log(300))\n","samples = [hyperopt.pyll.stochastic.sample(min_samples_split) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"-QZxkSVCekHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best = fmin(objective, space, algo = tpe.suggest, max_evals = 100, trials = trials)"],"metadata":{"id":"hfPgXfgqkTta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mostrar los mejores modelos"],"metadata":{"id":"WL1Y7m16kTtb"}},{"cell_type":"code","source":["df_res_hyperopt = pd.DataFrame(list(map(flatten, [e['result'] for e in trials.trials])))\n","df_res_hyperopt.sort_values('loss').head()"],"metadata":{"id":"aPCeNRMFkTtb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Guardar el dataframe (Descargarlo o cambiar el path para preservarlo)"],"metadata":{"id":"w1qfHQjrkTtb"}},{"cell_type":"code","source":["#df_res_hyperopt.to_pickle(\"df_res_hyperopt_RF\")\n","\n","# Para cargar el archivo de vuelta: \n","# df_res_hyperopt = pd.read_pickle(\"df_res_hyperopt\") "],"metadata":{"id":"f1LMedBBkTtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_res_hyperopt = pd.read_pickle(\"/content/gdrive/MyDrive/Machine Learning/TP3/df_res_hyperopt_SVM\") "],"metadata":{"id":"ZHCT5T8rkTtb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graficar los errores de Train (naranja) y Dev (azul) y mostrar el mejor modelo "],"metadata":{"id":"27hzpEJxkTtb"}},{"cell_type":"code","source":["df_res_hyperopt.loss.plot(style='-o', alpha=0.5)\n","plt.scatter([df_res_hyperopt.loss.argmin()], [df_res_hyperopt.loss.min()], c='r')\n","df_res_hyperopt.tr_loss.plot()\n","plt.yscale('log')\n","plt.grid()"],"metadata":{"id":"Q-8SJUz3kTtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,6))\n","plt.scatter(df_res_hyperopt.tr_loss, df_res_hyperopt.loss, c=(df_res_hyperopt.loss-df_res_hyperopt.tr_loss)/df_res_hyperopt.loss*100)\n","plt.title('Comparison of training and dev losses.\\n Color corresponds to overfitting percentage')\n","plt.colorbar()\n","m = min(df_res_hyperopt.tr_loss.min(), df_res_hyperopt.loss.min())\n","M = max(df_res_hyperopt.tr_loss.max(), df_res_hyperopt.loss.max())\n","plt.plot([m, M], [m, M], 'k--')\n","plt.xlabel('tr loss')\n","plt.ylabel('dev loss')\n","plt.grid()"],"metadata":{"id":"oANgyNGmkTtc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mostrar la distribución de los hiperparámetros para los mejores y peores modelos"],"metadata":{"id":"1Y3rb_9OkTtc"}},{"cell_type":"code","source":["df = df_res_hyperopt\n","cut_point = df.loss.median()\n","best_models_df = df[df.loss <= cut_point]\n","worst_models_df = df[df.loss > cut_point]\n","\n","def visualize_param(param_name):\n","  s = df[f'params.{param_name}']\n","  if s.dtype.name == 'object':\n","    visualize_categorical_param(param_name)\n","  else: # assume numerical\n","    visualize_numerical_param(param_name)\n","\n","def visualize_categorical_param(param_name):\n","    pd.concat([\n","      best_models_df[f'params.{param_name}'].value_counts().rename('best'),\n","      worst_models_df[f'params.{param_name}'].value_counts().rename('worst')\n","  ], axis=1).plot.bar()\n","\n","def visualize_numerical_param(param_name):\n","  plt.violinplot([\n","      best_models_df[f'params.{param_name}'],\n","      worst_models_df[f'params.{param_name}']\n","  ])\n","  plt.xticks([1, 2], ['best', 'worst'])"],"metadata":{"id":"SVjB_Nb7kTtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# param_names = list(trials.trials[0]['result']['params'].keys())\n","# for param_name in param_names:\n","#   plt.figure()\n","#   visualize_param(param_name)\n","#   plt.title(param_name)\n","#   plt.tight_layout()"],"metadata":{"id":"S1u5hyXekTtc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Buscar el modelo que menos sobreajusta"],"metadata":{"id":"IRNC74iVkTtc"}},{"cell_type":"code","source":["# El que menos overfittea de los mejors\n","best = df[df.loss < df.loss.min() * 1.001].sort_values('tr_loss', ascending = False).head(30)\n","best"],"metadata":{"id":"7r52zrLokTtc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" RF  calibrado y optimizado"],"metadata":{"id":"peApsmY9kTtd"}},{"cell_type":"code","source":["params = {k.replace('params.', ''):v for k, v in best.iloc[0].to_dict().items() if 'params.' in k}\n","# Tenemos que hacer una adaptacion a nuestra funcion evaluate_model para que funcione con hyperopt\n","if params['min_samples_split'] is not None:\n","    params['min_samples_split'] = int(params['min_samples_split'])\n","    params['max_features'] = int(params['max_features'])\n","    params['n_estimators'] = int(params['n_estimators'])\n","RF_Uncalibrated_Pipe = make_pipeline(\n","    preprocessor1, \n","    RandomForestClassifier(random_state = 420, class_weight= 'balanced', **params) \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(RF_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes = dict(\n","            name = \"Mejor modelo RF\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes"],"metadata":{"id":"wR2P12EgkTtd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cambiando el \"preprocesor\" pipe por el \"preprocessor3\" pipe"],"metadata":{"id":"GnZEU7i6kTtd"}},{"cell_type":"code","source":["# Tenemos que hacer una adaptacion a nuestra funcion evaluate_model para que funcione con hyperopt\n","if params['min_samples_split'] is not None:\n","    params['min_samples_split'] = int(params['min_samples_split'])\n","    params['max_features'] = int(params['max_features'])\n","    params['n_estimators'] = int(params['n_estimators'])\n","RF_Uncalibrated_Pipe2 = make_pipeline(\n","    preprocessor3, \n","    RandomForestClassifier(random_state = 420, class_weight= 'balanced', **params)  \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(RF_Uncalibrated_Pipe2, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes2 = dict(\n","            name = \"Mejor modelo RF\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes2"],"metadata":{"id":"HiQGE3crkTtd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_time"],"metadata":{"id":"t8EE28tmkTtd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluar el nivel de calibración de las probabilidades con un Diagrama de Confiabilidad"],"metadata":{"id":"h2JP3XofkTte"}},{"cell_type":"markdown","source":["### Calibración con el dataset de Development"],"metadata":{"id":"3-g4QUO4kTte"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(RF_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","probs = calibrated.predict_proba(xdev)[:,1]\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle = '--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"YKz7CI9CkTte"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Calibración con el dataset de Testing"],"metadata":{"id":"jtxW5uOqkTte"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.make_calibration_curve('CalibratedSMV', RF_Uncalibrated_Pipe)"],"metadata":{"id":"MvKcdZvfkTte"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Con otros hiperparámetros se obtiene un rendimiento similar y al mismo \n","tiempo los errores de train, dev y test son más parejos"],"metadata":{"id":"7Rq23r4DrXM7"}},{"cell_type":"code","source":["df_res_hyperopt = pd.DataFrame(list(map(flatten, [e['result'] for e in trials.trials])))\n","df_res_hyperopt.sort_values('loss').head()"],"metadata":{"id":"mH08scb9rtYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install import_ipynb"],"metadata":{"id":"_FDPfAQo_UOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"36kfNxhL_UOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd \"/content/gdrive/My Drive/Machine Learning/TP3\"\n"],"metadata":{"id":"LkaG7zVT_UOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"ckCVdUzQ_UOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FJz3Qit_UOl"},"outputs":[],"source":["import import_ipynb\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline, make_union\n","from sklearn.compose import ColumnTransformer, make_column_transformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from collections import Counter\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.calibration import calibration_curve\n","#from Lib import Evaluator\n","from Lib import BMI_imputer\n","from Lib import SmokingStatus_toNan\n","from Lib import SmokingStatus_imputer\n","from Lib import graficar_distribuciones_Train_Data\n","from Lib import graficar_distribuciones_Dev_Data\n","from Lib import flatten\n","from sklearn.metrics import log_loss\n","from matplotlib import pyplot\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","import math"]},{"cell_type":"markdown","source":["## Path to the data on Drive"],"metadata":{"id":"fKvagka4_UOl"}},{"cell_type":"code","source":["DATA_HOME = r\"/content/gdrive/MyDrive/Machine Learning/TP1/\"\n","df = pd.read_csv(\n","    DATA_HOME + \"/healthcare-dataset-stroke-data.csv\"\n",")"],"metadata":{"id":"vyMouDVj_UOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"czHAvx6Z_UOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Limpieza de observaciones malas y particion x e y"],"metadata":{"id":"T1TPr-AN_UOm"}},{"cell_type":"code","source":["df = df[df.gender != \"Other\"]\n","df = df.drop([\"work_type\",\t\"Residence_type\", \"id\"], axis=1)"],"metadata":{"id":"Uv8O6ANX_UOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ydf = df[\"stroke\"]\n","xdf = df.loc[:, df.columns != \"stroke\"]"],"metadata":{"id":"Gx_ajKOz_UOm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Division de dataset para validacion cruzada"],"metadata":{"id":"UC_l_NIS_UOm"}},{"cell_type":"code","source":["xtrain, xdev, ytrain, ydev = train_test_split(xdf, ydf, stratify=ydf, test_size=1/5, random_state=420)"],"metadata":{"id":"DIlFlAdq_UOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xdev, xtest, ydev, ytest = train_test_split(xdev, ydev, stratify=ydev, test_size=1/2, random_state=420)"],"metadata":{"id":"MzFhU4Cy_UOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrA15wAw_UOn"},"outputs":[],"source":["from sklearn.metrics import log_loss\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.calibration import calibration_curve\n","from matplotlib import pyplot\n","\n","class Evaluator:\n","    def __init__(self, X_train, y_train, X_dev, y_dev, X_test=None, y_test=None):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.X_dev = X_dev\n","        self.y_dev = y_dev\n","        self.X_test = X_test\n","        self.y_test = y_test\n","        self.evaluations = []\n","\n","    def eval_pipe(self, model_name, pipe): \n","        res = self.eval_prediction(model_name, pipe.predict_proba(self.X_train)[:,1], pipe.predict_proba(self.X_dev)[:,1])\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, pipe.predict_proba(self.X_test)[:,1])\n","        return res\n","\n","    def fit_and_eval_pipe(self, model_name, pipe): \n","        pipe.fit(self.X_train, self.y_train)\n","        res = self.eval_prediction(model_name, pipe.decision_function(self.X_train), pipe.decision_function(self.X_dev))\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, pipe.decision_function(self.X_test))\n","        return res\n","\n","    def eval_pipe_calibrated(self, model_name, pipe): \n","        #calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv = 10)\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv = 10)\n","        calibrated.fit(self.X_train, self.y_train)\n","        res = self.eval_prediction(model_name, calibrated.predict_proba(self.X_train)[:,1], calibrated.predict_proba(self.X_dev)[:,1])\n","        if self.X_test is not None:\n","            res['test'] = log_loss(self.y_test, calibrated.predict_proba(self.X_test)[:,1])\n","        return res\n","\n","    def make_calibration_curve(self, model_name, pipe):\n","      if self.X_test is not None:\n","        # calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv=5)\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv=10)\n","        calibrated.fit(self.X_train, self.y_train)\n","        probs = calibrated.predict_proba(self.X_test)[:,1]\n","        # reliability diagram\n","        fop, mpv = calibration_curve(self.y_test, probs, n_bins = 10, normalize = True)\n","        # plot perfectly calibrated\n","        pyplot.plot([0, 1], [0, 1], linestyle='--')\n","        # plot model reliability\n","        pyplot.plot(mpv, fop, marker='.')\n","        pyplot.show()\n","      else:\n","        calibrated = CalibratedClassifierCV(pipe, method = 'isotonic', cv=10)\n","        # calibrated = CalibratedClassifierCV(pipe, method = 'sigmoid', cv=5)\n","        calibrated.fit(self.X_train, self.y_train)\n","        probs = calibrated.predict_proba(self.X_dev)[:,1]\n","        # reliability diagram\n","        fop, mpv = calibration_curve(self.y_dev, probs, n_bins=10, normalize=True)\n","        # plot perfectly calibrated\n","        pyplot.plot([0, 1], [0, 1], linestyle='--')\n","        # plot model reliability\n","        pyplot.plot(mpv, fop, marker='.')\n","        pyplot.show()\n","\n","    def eval_prediction(self, model_name, y_hat_train, y_hat_dev):\n","        res = dict(\n","            name=model_name,\n","            train= log_loss(self.y_train, y_hat_train),\n","            dev  = log_loss(self.y_dev, y_hat_dev, )\n","        )\n","\n","        self.evaluations.append(res)\n","        return res"]},{"cell_type":"markdown","source":["## Crear las pipelines de operaciones sobre los datos"],"metadata":{"id":"5qaGhANZ_UOn"}},{"cell_type":"code","source":["bmi = ['bmi']\n","numericas = ['age', 'hypertension','avg_glucose_level']\n","categoricas = [\"gender\", \"ever_married\",\"smoking_status\",\"heart_disease\"]\n","\n","# pipes numericas\n","imputer_pipe = make_pipeline(\n","    SimpleImputer(missing_values=np.nan, strategy='mean'), \n",")\n","scaler_pipe = make_pipeline(\n","     StandardScaler()\n",")\n","# pipes categoricas\n","one_hot_pipe = make_pipeline(\n","    OneHotEncoder()\n",")\n","\n","# preprocessor   \n","preprocessor = make_column_transformer(\n","    (scaler_pipe, numericas),\n","    (imputer_pipe, bmi))\n","\n","# preprocessor 1  \n","preprocessor1 = make_column_transformer(\n","    (imputer_pipe, bmi),\n","    (scaler_pipe, numericas), \n","    (one_hot_pipe, categoricas))\n","\n","# preprocessor 2 \n","\n","preprocessor2 = make_pipeline(\n","    SmokingStatus_toNan(\"smoking_status\"),\n","    make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","    ), \n","    IterativeImputer(random_state=42)\n",")\n","\n","# preprocessor 3\n","preprocessor3 = make_pipeline(\n","     BMI_imputer(\"bmi\"), \n","     SmokingStatus_toNan(\"smoking_status\"),\n","     SmokingStatus_imputer(\"smoking_status\"),\n","     make_column_transformer(\n","        (scaler_pipe, numericas), \n","        (one_hot_pipe, categoricas)\n","      )\n","    )"],"metadata":{"id":"5JauK1r4_UOn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizar Diagramas de los pipelines de preprocesamiento de datos "],"metadata":{"id":"ecgHH-M4_UOo"}},{"cell_type":"code","source":["# visualizar diagrama \n","from sklearn import set_config\n","set_config(display='diagram')\n","display(preprocessor1) "],"metadata":{"id":"QYeTSNkD_UOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_config(display='diagram')\n","display(preprocessor2) "],"metadata":{"id":"Z7L4O5iS_UOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_config(display='diagram')\n","display(preprocessor3) "],"metadata":{"id":"G563auls_UOo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Establecer las pipelines con los modelos"],"metadata":{"id":"YJ15eU39_UOp"}},{"cell_type":"code","source":["# from collections import Counter\n","# # print(Counter(ytrain))\n","# oversample = RandomOverSampler(sampling_strategy = 0.7)\n","# xover, yover = oversample.fit_resample(xtrain, ytrain)\n","# print(Counter(yover))\n","# #4087/199\n","# #4087 - 199\n","# #sum(ytrain)\n"],"metadata":{"id":"9adSBTdJdd5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from imblearn.under_sampling import RandomUnderSampler\n","\n","# undersample = RandomUnderSampler(sampling_strategy = 'majority')\n","# xover, yover = undersample.fit_resample(xover, yover)\n","# print(Counter(yover))"],"metadata":{"id":"vGT4RfSqhoDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define GB pipeline:\n","over = RandomOverSampler(sampling_strategy = 0.7)\n","under = RandomUnderSampler(sampling_strategy = 'majority')\n","steps = [('o', over), ('u', under), ('model', GradientBoostingClassifier(random_state = 420, n_estimators = 20, learning_rate = 0.1,\n","                                 max_depth = 3))]\n","GB_pipe = Pipeline(steps=steps)"],"metadata":{"id":"6S5gZW8FIVJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GB_Uncalibrated_pipe = make_pipeline(\n","    preprocessor, \n","    GB_pipe  \n",")\n","\n","GB1_Uncalibrated_pipe = make_pipeline(\n","    preprocessor1, \n","    GB_pipe  \n",")\n","\n","GB2_Uncalibrated_pipe = make_pipeline(\n","    preprocessor2, \n","    GB_pipe \n",")\n","\n","GB3_Uncalibrated_pipe  = make_pipeline(\n","    preprocessor3, \n","    GB_pipe \n",")"],"metadata":{"id":"skHg4u0y_UOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","# ev.eval_pipe_calibrated('UncalibratedSMV', GB1_Uncalibrated_pipe)"],"metadata":{"id":"JhbxzbT2JYj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","\n","ev.eval_pipe_calibrated('solo GB', GB_Uncalibrated_pipe)"],"metadata":{"id":"z02tXnZuxBHT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Comparar la efectividad de un modelo GB descalibrado con uno calibrado"],"metadata":{"id":"9tOCTapb_UOt"}},{"cell_type":"markdown","source":["## GB descalibrado"],"metadata":{"id":"b0BEHpJh_UOt"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","GB1_Uncalibrated_pipe.fit(xtrain, ytrain)\n","ev.eval_pipe('UncalibratedSMV', GB1_Uncalibrated_pipe)"],"metadata":{"id":"LrDb3fSi_UOt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = GB1_Uncalibrated_pipe.predict_proba(xdev)[:,1]\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle='--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"jXsMRfws_UOu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GB calibrado"],"metadata":{"id":"VfUApeyQ_UOu"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.eval_pipe_calibrated('UncalibratedSMV', GB1_Uncalibrated_pipe)"],"metadata":{"id":"suIyTlsx_UOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","ev = Evaluator(xtrain, ytrain, xdev, ydev)\n","ev.make_calibration_curve('UncalibratedSMV', GB1_Uncalibrated_pipe)"],"metadata":{"id":"vZGh9fPT_UOu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Distribuciones de la variable respuesta con el Train Set"],"metadata":{"id":"gAYZW2cd_UOv"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(GB1_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Train_Data(xtrain, ytrain, calibrated)"],"metadata":{"id":"5uRupqQc_UOv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Distribuciones de la variable respuesta con el Dev Set\n"],"metadata":{"id":"7Zh3D8FJ_UOv"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(GB1_Uncalibrated_pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","graficar_distribuciones_Dev_Data(xdev, ydev, calibrated)"],"metadata":{"id":"mN2ta5RU_UOv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Comparar la efectividad de los modelos GB entrenados y probados con datasets preprocesados de tres manera diferentes "],"metadata":{"id":"gb4-fqDm_UOw"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","\n","ev.eval_pipe_calibrated('solo GB', GB_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('GB con SimpleImputer', GB1_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('GB con IterativeImputer de bmi', GB2_Uncalibrated_pipe)\n","ev.eval_pipe_calibrated('GB con regresion de bmi y DTC en ss', GB3_Uncalibrated_pipe)\n","\n","pd.DataFrame(ev.evaluations)"],"metadata":{"id":"j1Yxon6r_UOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Selección de Hiperparámetros en modelos GB"],"metadata":{"id":"zPxRrdrd_UOy"}},{"cell_type":"code","source":["from pprint import pprint\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from time import time\n","\n","\n","def objective(params):\n","    # Tenemos que hacer una adaptacion a nuestra funcion evaluate_model para que funcione con hyperopt\n","    params['n_estimators'] = int(params['n_estimators'])\n","    print(params)\n","    steps = [('o', over), ('u', under), ('model', GradientBoostingClassifier(random_state = 420, **params))]\n","    GB_pipe = Pipeline(steps = steps)\n","    GBUncalibrated_pipe = make_pipeline(\n","    preprocessor1, \n","    GB_pipe  \n","    )\n","    t0 = time()\n","    calibrated = CalibratedClassifierCV(GBUncalibrated_pipe, method = 'isotonic', cv = 10)\n","    calibrated.fit(xtrain, ytrain)\n","    train_time = time() - t0\n","    trainloss = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1])\n","    devloss = log_loss(ydev, calibrated.predict_proba(xdev)[:,1])\n","    testloss = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","    print(f'trainloss {trainloss:.02f}', f'devloss {devloss:.02f}', f'testloss {testloss:.02f}')\n","    return dict(\n","        tr_loss = trainloss,\n","        loss = devloss,\n","        test_loss = testloss,\n","        params = params,\n","        train_time = train_time,\n","        status=STATUS_OK\n","    )\n"],"metadata":{"id":"V1lo0JIH_UOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["space = {\n","    'n_estimators': hp.quniform('n_estimators', 10, 300, 10),\n","    'max_depth': hp.uniform('max_depth', 2, 8),\n","    'subsample': hp.uniform('subsample', 0.2, 1.0),\n","    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1))\n","}\n","\n","trials = Trials()"],"metadata":{"id":"NbWhy4Y7bzjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","n_estimators = hp.loguniform('gamma', low = np.log(0.01), high = np.log(3))\n","samples = [hyperopt.pyll.stochastic.sample(n_estimators) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"hLFEMOI__UOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","max_depth = hp.uniform('max_depth', 2, 8)\n","samples = [hyperopt.pyll.stochastic.sample(max_depth) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"QcPPQRqH_UOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import hyperopt.pyll.stochastic\n","\n","learning_rate = hp.loguniform('learning_rate', np.log(0.01), np.log(1))\n","samples = [hyperopt.pyll.stochastic.sample(learning_rate) for i in range(1000)]\n","plt.hist(samples)"],"metadata":{"id":"wvsDOZFy_UOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best = fmin(objective, space, algo = tpe.suggest, max_evals = 100, trials = trials)"],"metadata":{"id":"fhGD9RWk_UOz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mostrar los mejores modelos"],"metadata":{"id":"zZU2Gd8k_UOz"}},{"cell_type":"code","source":["df_res_hyperopt = pd.DataFrame(list(map(flatten, [e['result'] for e in trials.trials])))\n","df_res_hyperopt.sort_values('loss').head()"],"metadata":{"id":"_l_D5n5E_UO0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Guardar el dataframe (Descargarlo o cambiar el path para preservarlo)"],"metadata":{"id":"8EidUbp0_UO0"}},{"cell_type":"code","source":["df_res_hyperopt.to_pickle(\"df_res_hyperopt_GB\")\n","\n","# Para cargar el archivo de vuelta: \n","# df_res_hyperopt = pd.read_pickle(\"df_res_hyperopt\") "],"metadata":{"id":"MT-sptbN_UO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_res_hyperopt = pd.read_pickle(\"/content/gdrive/MyDrive/Machine Learning/TP3/df_res_hyperopt_SVM\") "],"metadata":{"id":"HWQLXNo1_UO0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Graficar los errores de Train (naranja) y Dev (azul) y mostrar el mejor modelo "],"metadata":{"id":"xkRAdszF_UO0"}},{"cell_type":"code","source":["df_res_hyperopt.loss.plot(style='-o', alpha=0.5)\n","plt.scatter([df_res_hyperopt.loss.argmin()], [df_res_hyperopt.loss.min()], c='r')\n","df_res_hyperopt.tr_loss.plot()\n","plt.yscale('log')\n","plt.grid()"],"metadata":{"id":"BEC_koXr_UO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,6))\n","plt.scatter(df_res_hyperopt.tr_loss, df_res_hyperopt.loss, c=(df_res_hyperopt.loss-df_res_hyperopt.tr_loss)/df_res_hyperopt.loss*100)\n","plt.title('Comparison of training and dev losses.\\n Color corresponds to overfitting percentage')\n","plt.colorbar()\n","m = min(df_res_hyperopt.tr_loss.min(), df_res_hyperopt.loss.min())\n","M = max(df_res_hyperopt.tr_loss.max(), df_res_hyperopt.loss.max())\n","plt.plot([m, M], [m, M], 'k--')\n","plt.xlabel('tr loss')\n","plt.ylabel('dev loss')\n","plt.grid()"],"metadata":{"id":"2FtRaIF7_UO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mostrar la distribución de los hiperparámetros para los mejores y peores modelos"],"metadata":{"id":"7QjtproM_UO1"}},{"cell_type":"code","source":["df = df_res_hyperopt\n","cut_point = df.loss.median()\n","best_models_df = df[df.loss <= cut_point]\n","worst_models_df = df[df.loss > cut_point]\n","\n","def visualize_param(param_name):\n","  s = df[f'params.{param_name}']\n","  if s.dtype.name == 'object':\n","    visualize_categorical_param(param_name)\n","  else: # assume numerical\n","    visualize_numerical_param(param_name)\n","\n","def visualize_categorical_param(param_name):\n","    pd.concat([\n","      best_models_df[f'params.{param_name}'].value_counts().rename('best'),\n","      worst_models_df[f'params.{param_name}'].value_counts().rename('worst')\n","  ], axis=1).plot.bar()\n","\n","def visualize_numerical_param(param_name):\n","  plt.violinplot([\n","      best_models_df[f'params.{param_name}'],\n","      worst_models_df[f'params.{param_name}']\n","  ])\n","  plt.xticks([1, 2], ['best', 'worst'])"],"metadata":{"id":"rTVbBFO2_UO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_names = list(trials.trials[0]['result']['params'].keys())\n","for param_name in param_names:\n","  plt.figure()\n","  visualize_param(param_name)\n","  plt.title(param_name)\n","  plt.tight_layout()"],"metadata":{"id":"g5KDT1C1_UO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Buscar el modelo que menos sobreajusta"],"metadata":{"id":"OIWBWFBd_UO2"}},{"cell_type":"code","source":["# El que menos overfittea de los mejors\n","best = df[df.loss < df.loss.min() * 1.001].sort_values('tr_loss', ascending = False).head(30)\n","best"],"metadata":{"id":"IQBZTjcO_UO2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GB  calibrado y optimizado"],"metadata":{"id":"8io8I5V6_UO2"}},{"cell_type":"code","source":["params = {k.replace('params.', ''):v for k, v in best.iloc[0].to_dict().items() if 'params.' in k}\n","params['n_estimators'] = int(params['n_estimators'])\n","print(params)\n","steps = [('o', over), ('u', under), ('model', GradientBoostingClassifier(random_state = 420, **params))]\n","GB_pipe = Pipeline(steps = steps)\n","GB_Uncalibrated_Pipe = make_pipeline(\n","preprocessor1, \n","GB_pipe  \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(GB_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes = dict(\n","            name = \"Mejor modelo GB\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes"],"metadata":{"id":"4a305J0H_UO2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cambiando el \"preprocesor\" pipe por el \"preprocessor3\" pipe"],"metadata":{"id":"awpvPMyo_UO2"}},{"cell_type":"code","source":["# Tenemos que hacer una adaptacion a nuestra funcion evaluate_model para que funcione con hyperopt\n","params['n_estimators'] = int(params['n_estimators'])\n","print(params)\n","steps = [('o', over), ('u', under), ('model', GradientBoostingClassifier(random_state = 420, **params))]\n","GB_pipe = Pipeline(steps = steps)\n","GB_Uncalibrated_Pipe2 = make_pipeline(\n","preprocessor3, \n","GB_pipe  \n",")\n","t0 = time()\n","calibrated = CalibratedClassifierCV(GB_Uncalibrated_Pipe2, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","train_time = time() - t0\n","BestModelRes2 = dict(\n","            name = \"Mejor modelo GB\",\n","            train_time = train_time,\n","            train = log_loss(ytrain, calibrated.predict_proba(xtrain)[:,1]),\n","            dev  = log_loss(ydev, calibrated.predict_proba(xdev)[:,1]),\n","            test = log_loss(ytest, calibrated.predict_proba(xtest)[:,1])\n","        )\n","BestModelRes2"],"metadata":{"id":"04OdZhyk_UO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_time"],"metadata":{"id":"vbh2unZ9_UO3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluar el nivel de calibración de las probabilidades con un Diagrama de Confiabilidad"],"metadata":{"id":"5Rr0Roim_UO3"}},{"cell_type":"markdown","source":["## Calibración con el dataset de Development"],"metadata":{"id":"_Juw3dqx_UO3"}},{"cell_type":"code","source":["calibrated = CalibratedClassifierCV(GB_Uncalibrated_Pipe, method = 'isotonic', cv = 10)\n","calibrated.fit(xtrain, ytrain)\n","probs = calibrated.predict_proba(xdev)[:,1]\n","# reliability diagram\n","fop, mpv = calibration_curve(ydev, probs, n_bins = 10, normalize = True)\n","# plot perfectly calibrated\n","pyplot.plot([0, 1], [0, 1], linestyle = '--')\n","# plot model reliability\n","pyplot.plot(mpv, fop, marker='.')\n","pyplot.show()"],"metadata":{"id":"bZ9fo807_UO3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Calibración con el dataset de Testing"],"metadata":{"id":"x3P88n8J_UO4"}},{"cell_type":"code","source":["ev = Evaluator(xtrain, ytrain, xdev, ydev, xtest, ytest)\n","ev.make_calibration_curve('CalibratedSMV', GB_Uncalibrated_Pipe)"],"metadata":{"id":"vXM-Wtsw_UO4"},"execution_count":null,"outputs":[]}]}